{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment for Day 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Task is to remove all commas and fullstop using regex.</li>\n",
    "<li>Step two is to use lemmatization on the story</li>\n",
    "<li>Step three is to remove stopwords from it</li>\n",
    "<li>Find entity for the first two lines of the story (NER)</li>\n",
    "<li>Create BAG OF WORDS Model of the whole story and add the first digit of all the vectors obtained and print the sum</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk   #Package for NLP\n",
    "import numpy as np\n",
    "nltk.download('punkt')   #It is used for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\" A gentleman was walking through an elephant camp, and he spotted that \n",
    "the elephants weren’t being kept in cages or held by the use of chains.\n",
    "All that was holding them back from escaping the camp, was a small piece of rope tied to one of their legs.\n",
    "As the man gazed upon the elephants, he was completely confused as to why the \n",
    "elephants didn’t just use their strength to break the rope and escape the camp. \n",
    "They could easily have done so, but instead, they didn’t try to at all.\n",
    "\n",
    "Curious and wanting to know the answer, he asked a trainer nearby why the elephants were\n",
    "just standing there and never tried to escape.\n",
    "The trainer replied;\n",
    "\n",
    "“when they are very young and much smaller we use the same size rope to tie them and, at that age, it’s enough to hold them. \n",
    "As they grow up, they are conditioned to believe they cannot break away. \n",
    "They believe the rope can still hold them, so they never try to break free.”\n",
    "\n",
    "The only reason that the elephants weren’t breaking \n",
    "free and escaping from the camp was that over time they adopted the belief that it just wasn’t possible.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' A gentleman was walking through an elephant camp, and he spotted that \\nthe elephants weren’t being kept in cages or held by the use of chains.', 'All that was holding them back from escaping the camp, was a small piece of rope tied to one of their legs.', 'As the man gazed upon the elephants, he was completely confused as to why the \\nelephants didn’t just use their strength to break the rope and escape the camp.', 'They could easily have done so, but instead, they didn’t try to at all.', 'Curious and wanting to know the answer, he asked a trainer nearby why the elephants were\\njust standing there and never tried to escape.', 'The trainer replied;\\n\\n“when they are very young and much smaller we use the same size rope to tie them and, at that age, it’s enough to hold them.', 'As they grow up, they are conditioned to believe they cannot break away.', 'They believe the rope can still hold them, so they never try to break free.”\\n\\nThe only reason that the elephants weren’t breaking \\nfree and escaping from the camp was that over time they adopted the belief that it just wasn’t possible.']\n",
      "['A', 'gentleman', 'was', 'walking', 'through', 'an', 'elephant', 'camp', ',', 'and', 'he', 'spotted', 'that', 'the', 'elephants', 'weren', '’', 't', 'being', 'kept', 'in', 'cages', 'or', 'held', 'by', 'the', 'use', 'of', 'chains', '.', 'All', 'that', 'was', 'holding', 'them', 'back', 'from', 'escaping', 'the', 'camp', ',', 'was', 'a', 'small', 'piece', 'of', 'rope', 'tied', 'to', 'one', 'of', 'their', 'legs', '.', 'As', 'the', 'man', 'gazed', 'upon', 'the', 'elephants', ',', 'he', 'was', 'completely', 'confused', 'as', 'to', 'why', 'the', 'elephants', 'didn', '’', 't', 'just', 'use', 'their', 'strength', 'to', 'break', 'the', 'rope', 'and', 'escape', 'the', 'camp', '.', 'They', 'could', 'easily', 'have', 'done', 'so', ',', 'but', 'instead', ',', 'they', 'didn', '’', 't', 'try', 'to', 'at', 'all', '.', 'Curious', 'and', 'wanting', 'to', 'know', 'the', 'answer', ',', 'he', 'asked', 'a', 'trainer', 'nearby', 'why', 'the', 'elephants', 'were', 'just', 'standing', 'there', 'and', 'never', 'tried', 'to', 'escape', '.', 'The', 'trainer', 'replied', ';', '“', 'when', 'they', 'are', 'very', 'young', 'and', 'much', 'smaller', 'we', 'use', 'the', 'same', 'size', 'rope', 'to', 'tie', 'them', 'and', ',', 'at', 'that', 'age', ',', 'it', '’', 's', 'enough', 'to', 'hold', 'them', '.', 'As', 'they', 'grow', 'up', ',', 'they', 'are', 'conditioned', 'to', 'believe', 'they', 'can', 'not', 'break', 'away', '.', 'They', 'believe', 'the', 'rope', 'can', 'still', 'hold', 'them', ',', 'so', 'they', 'never', 'try', 'to', 'break', 'free.', '”', 'The', 'only', 'reason', 'that', 'the', 'elephants', 'weren', '’', 't', 'breaking', 'free', 'and', 'escaping', 'from', 'the', 'camp', 'was', 'that', 'over', 'time', 'they', 'adopted', 'the', 'belief', 'that', 'it', 'just', 'wasn', '’', 't', 'possible', '.']\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(story)   #Sentence tokenizer\n",
    "words = nltk.word_tokenize(story)   #Word tokenizer\n",
    "\n",
    "print(sentences) #See sentences are tokenized\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') #STOP WORDS DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    sentences[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A gentleman walking elephant camp , spotted elephants ’ kept cages held use chains .', 'All holding back escaping camp , small piece rope tied one legs .', 'As man gazed upon elephants , completely confused elephants ’ use strength break rope escape camp .', 'They could easily done , instead , ’ try .', 'Curious wanting know answer , asked trainer nearby elephants standing never tried escape .', 'The trainer replied ; “ young much smaller use size rope tie , age , ’ enough hold .', 'As grow , conditioned believe break away .', 'They believe rope still hold , never try break free. ” The reason elephants ’ breaking free escaping camp time adopted belief ’ possible .']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Noise\n",
    "\n",
    "### Removing comma, fullstop and extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re   # For regex\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = sentences[i].lower()\n",
    "    sentences[i] = re.sub(r'\\W',' ', sentences[i])   # '\\W' means everything except Alphabet and Digits \n",
    "    sentences[i]=  re.sub(r'\\s+',' ',sentences[i])   # Removes extra whitespaces and gives only one whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a gentleman walking elephant camp spotted elephants kept cages held use chains ',\n",
       " 'all holding back escaping camp small piece rope tied one legs ',\n",
       " 'as man gazed upon elephants completely confused elephants use strength break rope escape camp ',\n",
       " 'they could easily done instead try ',\n",
       " 'curious wanting know answer asked trainer nearby elephants standing never tried escape ',\n",
       " 'the trainer replied young much smaller use size rope tie age enough hold ',\n",
       " 'as grow conditioned believe break away ',\n",
       " 'they believe rope still hold never try break free the reason elephants breaking free escaping camp time adopted belief possible ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet') #LIBRARY HAVING STEMMED WORDS (DICTIONARY)\n",
    "nltk.download('averaged_perceptron_tagger')  #DICTIONARY FOR POS TAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a gentleman walk elephant camp spot elephant keep cage hold use chain',\n",
       " 'all hold back escape camp small piece rope tie one leg',\n",
       " 'as man gaze upon elephant completely confuse elephant use strength break rope escape camp',\n",
       " 'they could easily do instead try',\n",
       " 'curious want know answer ask trainer nearby elephant stand never try escape',\n",
       " 'the trainer reply young much smaller use size rope tie age enough hold',\n",
       " 'as grow condition believe break away',\n",
       " 'they believe rope still hold never try break free the reason elephant break free escape camp time adopt belief possible']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "lemmed_sentences = []\n",
    "for i in range(len(sentences)):\n",
    "    lemma_words = []\n",
    "    sent = ''\n",
    "    for word, tag in pos_tag(word_tokenize(sentences[i])):\n",
    "        lemtag = tag[0].lower()    # lowercase the firsr letter of tag word\n",
    "        lemtag = lemtag if lemtag in ['a','r','n','v'] else None\n",
    "        if not lemtag:\n",
    "            lemma = word\n",
    "        else:\n",
    "            lemma = lem.lemmatize(word,lemtag)\n",
    "        lemma_words.append(lemma)\n",
    "    sent = ' '.join(lemma_words)\n",
    "    lemmed_sentences.append(sent)\n",
    "    \n",
    "lemmed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a gentleman walk elephant camp spot elephant keep cage hold use chain', 'all hold back escape camp small piece rope tie one leg', 'as man gaze upon elephant completely confuse elephant use strength break rope escape camp', 'they could easily do instead try', 'curious want know answer ask trainer nearby elephant stand never try escape', 'the trainer reply young much smaller use size rope tie age enough hold', 'as grow condition believe break away', 'they believe rope still hold never try break free the reason elephant break free escape camp time adopt belief possible']\n"
     ]
    }
   ],
   "source": [
    "print(lemmed_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')   # Name Entity Recognition\n",
    "nltk.download('words')   # To download the dictionionary of all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = sentences[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(paragraph)):\n",
    "    words = nltk.word_tokenize(paragraph[i])\n",
    "    tagged_words=  nltk.pos_tag(words)\n",
    "    namedEnt = nltk.ne_chunk(tagged_words)\n",
    "    namedEnt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re   #Library for regex\n",
    "import heapq  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'gentleman': 1, 'walking': 1, 'elephant': 1, 'camp': 4, 'spotted': 1, 'elephants': 5, 'kept': 1, 'cages': 1, 'held': 1, 'use': 3, 'chains': 1, 'all': 1, 'holding': 1, 'back': 1, 'escaping': 2, 'small': 1, 'piece': 1, 'rope': 4, 'tied': 1, 'one': 1, 'legs': 1, 'as': 2, 'man': 1, 'gazed': 1, 'upon': 1, 'completely': 1, 'confused': 1, 'strength': 1, 'break': 3, 'escape': 2, 'they': 2, 'could': 1, 'easily': 1, 'done': 1, 'instead': 1, 'try': 2, 'curious': 1, 'wanting': 1, 'know': 1, 'answer': 1, 'asked': 1, 'trainer': 2, 'nearby': 1, 'standing': 1, 'never': 2, 'tried': 1, 'the': 2, 'replied': 1, 'young': 1, 'much': 1, 'smaller': 1, 'size': 1, 'tie': 1, 'age': 1, 'enough': 1, 'hold': 2, 'grow': 1, 'conditioned': 1, 'believe': 2, 'away': 1, 'still': 1, 'free': 2, 'reason': 1, 'breaking': 1, 'time': 1, 'adopted': 1, 'belief': 1, 'possible': 1}\n"
     ]
    }
   ],
   "source": [
    "# Creating Word Histogram\n",
    "\n",
    "wordcount = {}\n",
    "for i in sentences:\n",
    "    words = nltk.word_tokenize(i)\n",
    "    for word in words:\n",
    "        if word in wordcount.keys():\n",
    "            wordcount[word] += 1\n",
    "        else:\n",
    "            wordcount[word] = 1\n",
    "            \n",
    "print(wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elephants', 'camp', 'rope', 'use', 'break', 'escaping', 'as', 'escape', 'they', 'try', 'trainer', 'never', 'the', 'hold', 'believe', 'free', 'a', 'gentleman', 'walking', 'elephant', 'spotted', 'kept', 'cages', 'held', 'chains', 'all', 'holding', 'back', 'small', 'piece', 'tied', 'one', 'legs', 'man', 'gazed', 'upon', 'completely', 'confused', 'strength', 'could', 'easily', 'done', 'instead', 'curious', 'wanting', 'know', 'answer', 'asked', 'nearby', 'standing', 'tried', 'replied', 'young', 'much', 'smaller', 'size', 'tie', 'age', 'enough', 'grow', 'conditioned', 'away', 'still', 'reason', 'breaking', 'time', 'adopted', 'belief', 'possible']\n"
     ]
    }
   ],
   "source": [
    "# Selecting 100 best features\n",
    "\n",
    "# (frequency, dictionary, creates vector of number of time a key is repeated)\n",
    "freq_words = heapq.nlargest(100,wordcount,key=wordcount.get)\n",
    "\n",
    "print(freq_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Vectors for Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Sentences to vectors\n",
    "\n",
    "X = []\n",
    "for data in sentences:\n",
    "    vector = []\n",
    "    for word in freq_words:   # iterate through every word of freq_words\n",
    "        if word in nltk.word_tokenize(data):   # if freq_word matches with word of sentence \n",
    "            vector.append(1)\n",
    "        else:\n",
    "            vector.append(0)\n",
    "    X.append(vector)   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of first digit of all the vectors obtained: 4\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in X:\n",
    "    c = c + i[0]\n",
    "    \n",
    "print(\"Sum of first digit of all the vectors obtained: {}\".format(c) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
