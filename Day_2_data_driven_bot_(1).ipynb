{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xImuydKNPpIk"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6CdL9ulEPpIr"
   },
   "outputs": [],
   "source": [
    "para = \"\"\"I am chatbot. How can i help you?. My father name is Shubham and i don't have my mother as i was born from my father. \n",
    "You know what's the best thing about MAD? MAD is the startup that not only helps to learn, but also helps to grow and form the\n",
    "world's best community around. It's goal is certainly the mission #learn&earn. It's mission is to give everyone what they deserve :\n",
    "A better education and better life. No i am not kidding, it's truth. Yes i am AatmaNirbhar and i guess everyone should be Aatmanirbhar!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oARWe0enae5M"
   },
   "outputs": [],
   "source": [
    "# Lower the case\n",
    "para = para.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "N7k-WooqPpI2",
    "outputId": "d095f1b3-565b-4fa8-a5a3-5e5dedef5c65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "sent_tokens = nltk.sent_tokenize(para)\n",
    "word_tokens = nltk.word_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eEw-wFpbPpI6"
   },
   "outputs": [],
   "source": [
    "# Lemmitization\n",
    "\n",
    "lemmer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dKOARR8gPpI-"
   },
   "outputs": [],
   "source": [
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]    # iterate through every token and lemmatize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fl28TZ0fPpJD"
   },
   "outputs": [],
   "source": [
    "# string.punctuation has all the punctuations\n",
    "# ord(punct) convert punctuation to its ASCII value\n",
    "# dict contains {ASCII: None} for punctuation mark\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "# remove_punct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "epLmEctdPpJI"
   },
   "outputs": [],
   "source": [
    "# This will return the word to LemTokens after Word tokenize, lowering its case and removing punctuation mark\n",
    "# translate will find punctuation mark in remove_punct_dict and if found replace it with None\n",
    "\n",
    "def Normalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ez89h-r3PpJM"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer   # For Tfid Vectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity   # For cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDtLQ8bRPpJQ"
   },
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)   # Appending the Question user ask to sent_tokens\n",
    "    TfidfVec = TfidfVectorizer(tokenizer = Normalize, stop_words='english')    #tokenizer ask about Pre processing and remove StopWords\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)     # vals has [[0,0,3]] Do cosine similarity between last vectors and all the vectors\n",
    "    idx = vals.argsort()[0][-2]     # 0 means 0th list of vals ,it has index of second last index i.e. index of second highest value after sorting the cosine_similarity\n",
    "    \n",
    "    flat = vals.flatten()    # [[0,0,3]] -> [0,0,3] this will make a single list of vals which is list inside a list\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]  # this contains tfid value of second highest cosine similarity\n",
    "\n",
    "    if(req_tfidf == 0):    # 0 means there is no similarity between the question and answer\n",
    "        robo_response = robo_response+\"I am sorry! I don't understand you\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response + sent_tokens[idx]    # return the sentences at index -2 as answer\n",
    "        return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "2-lh-OMAPpJW",
    "outputId": "756a4818-2815-44e1-dd6e-95775567e90d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAD: My name is MADbot. I will answer everything about myself. If you want to exit, type Bye!\n",
      "\n",
      "MAD: I am sorry! I don't understand you\n",
      "are YOU aatmanirbhar\n",
      "MAD: yes i am aatmanirbhar and i guess everyone should be aatmanirbhar!\n",
      "who is you FATHER\n",
      "MAD: my father name is shubham and i don't have my mother as i was born from my father.\n",
      "thank\n",
      "MAD: I am sorry! I don't understand you\n",
      "bye\n",
      "MAD: Bye! Stay MAD Stay Creative.\n"
     ]
    }
   ],
   "source": [
    "# for chatbot reply\n",
    "\n",
    "flag=True\n",
    "print(\"MAD: My name is MADbot. I will answer everything about myself. If you want to exit, type Bye!\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"MAD: You are welcome..\")\n",
    "        else:\n",
    "            print(\"MAD: \",end=\"\")\n",
    "            print(response(user_response))\n",
    "            sent_tokens.remove(user_response)   # remove user question from sent_token      \n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"MAD: Bye! Stay MAD Stay Creative.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OdaTH01JPpJc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day 2 data_driven_bot_(1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
